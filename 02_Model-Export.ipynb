{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "LDL01RiXu5wJ",
    "outputId": "1b67a593-f4c7-43f2-8262-9f7c6e920537"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import load_model\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.framework import graph_io\n",
    "\n",
    "tf.__version__\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09I4lRl1u5wP",
    "outputId": "75117829-f942-4b35-a9f6-5f1088b9aa26"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping: no known devices.\n"
     ]
    }
   ],
   "source": [
    "# If GPU is not available: \n",
    "# GPU_USE = '/cpu:0'\n",
    "# config = tf.compat.v1.ConfigProto(device_count = {\"GPU\": 0})\n",
    "\n",
    "\n",
    "# If GPU is available: \n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.log_device_placement = True\n",
    "# Allow dynamic allocation of GPU memory\n",
    "config.allow_soft_placement = True\n",
    "# The memory is managed in blocks, and space allocation and release are performed by blocks\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "# Limit the maximum memory used\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "\n",
    "# set session config\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIPNw7heu5wQ"
   },
   "source": [
    "## Define input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "r8EoJmDKu5wQ"
   },
   "outputs": [],
   "source": [
    "input_file = \"myModel.h5\"\n",
    "\n",
    "output_file = \"myModel.pb\"\n",
    "\n",
    "output_node_prefix = \"output_node\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NpSu4WG4u5wQ",
    "outputId": "da848a52-53e8-418f-de69-e939732998b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "output nodes names are:  ['output_node0']\n",
      "['output_node0']\n",
      "output_node0\n"
     ]
    }
   ],
   "source": [
    "K.set_learning_phase(0)\n",
    "net_model = load_model(input_file)\n",
    "\n",
    "num_output = 1\n",
    "pred = [None]*num_output\n",
    "pred_node_names = [None]*num_output\n",
    "for i in range(num_output):\n",
    "    print(i)\n",
    "    pred_node_names[i] = output_node_prefix+str(i)\n",
    "    # Return a Tensor with the same shape and contents as input\n",
    "    pred[i] = tf.identity(net_model.outputs[i], name=pred_node_names[i])\n",
    "print('output nodes names are: ', pred_node_names)\n",
    "output_node_prefix = pred_node_names[0]\n",
    "print(pred_node_names)\n",
    "print(output_node_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1cMn7rCpu5wQ"
   },
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.keras.backend.get_session()\n",
    "sess.graph.as_graph_def()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1qW8J-K_u5wR"
   },
   "source": [
    "## Export model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replace all the variables in the graph with constants of the same values. This makes it possible to describe the network fully with a single GraphDef file, and allows the removal of a lot of ops related to loading and saving the variables. It is very convenient to only have a single file for deployment in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UMZF2L5-u5wR",
    "outputId": "cadc70f1-4fee-41ef-9733-00071aacad06"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3a125c841abe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconstant_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_variables_to_constants\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_graph_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_node_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgraph_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstant_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saved the freezed graph at: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "constant_graph = tf.compat.v1.graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n",
    "graph_io.write_graph(constant_graph, \"\",output_file, as_text=False)\n",
    "\n",
    "print('Saved the freezed graph at: ', (output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9mDfIE1uu5wR"
   },
   "source": [
    "## Show input and output node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ObsJA4Smu5wR",
    "outputId": "0d21ab78-730f-49ab-9fb8-eddcfa4ed2dc"
   },
   "outputs": [],
   "source": [
    "g = tf.compat.v1.GraphDef()\n",
    "g.ParseFromString(open(output_file, \"rb\").read())\n",
    "s = \"\"\n",
    "for n in g.node:\n",
    "    s =s + str(n.name) + \"\\n\"\n",
    "\n",
    "print(s)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "02_Model-Export.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
